{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katiezchang/UNEP/blob/main/ass8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "runl4romaRB6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from typing import Optional, Dict, Any, List\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "import psycopg2\n",
        "from psycopg2.extras import Json as PgJson\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# DB (Supabase Postgres â€“ session pooler)\n",
        "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
        "# SECURITY: Set DB_PASSWORD environment variable, do not hardcode passwords\n",
        "DB_PASSWORD = os.getenv(\"DB_PASSWORD\", \"\")\n",
        "DB_HOST = os.getenv(\"DB_HOST\", \"pooler.tulbxwdifnzquliytsog.supabase.co\")\n",
        "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
        "DB_NAME = os.getenv(\"DB_NAME\", \"postgres\")\n",
        "COUNTRIES_TABLE = \"countries\"\n",
        "\n",
        "BUR_LISTING_URL = \"https://unfccc.int/BURs\"\n",
        "\n",
        "BUR_PDF_DIR = \"bur_pdfs\"\n",
        "os.makedirs(BUR_PDF_DIR, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "24_0i7_ibntQ"
      },
      "outputs": [],
      "source": [
        "def get_db_conn():\n",
        "    return psycopg2.connect(\n",
        "        user=DB_USER,\n",
        "        password=DB_PASSWORD,\n",
        "        host=DB_HOST,\n",
        "        port=DB_PORT,\n",
        "        dbname=DB_NAME,\n",
        "        sslmode=\"require\",\n",
        "    )\n",
        "\n",
        "\n",
        "def get_country_row(country: str) -> Optional[Dict[str, Any]]:\n",
        "    conn = get_db_conn()\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        cur.execute(\n",
        "            f\"SELECT id, name, sections FROM {COUNTRIES_TABLE} WHERE name = %s\",\n",
        "            (country,),\n",
        "        )\n",
        "        row = cur.fetchone()\n",
        "        if not row:\n",
        "            return None\n",
        "        row_id, name, sections = row\n",
        "        if isinstance(sections, str):\n",
        "            sections = json.loads(sections)\n",
        "        elif sections is None:\n",
        "            sections = {}\n",
        "        return {\"id\": row_id, \"name\": name, \"sections\": sections}\n",
        "    finally:\n",
        "        conn.close()\n",
        "\n",
        "\n",
        "def upsert_country_sections(country: str, new_sections: Dict[str, Dict[str, str]]):\n",
        "    existing = get_country_row(country)\n",
        "    conn = get_db_conn()\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        if existing:\n",
        "            merged = {**(existing[\"sections\"] or {}), **new_sections}\n",
        "            cur.execute(\n",
        "                f\"\"\"\n",
        "                UPDATE {COUNTRIES_TABLE}\n",
        "                SET sections = %s\n",
        "                WHERE id = %s\n",
        "                \"\"\",\n",
        "                (PgJson(merged), existing[\"id\"]),\n",
        "            )\n",
        "            print(f\"[DB] Updated sections for {country} (id={existing['id']}).\")\n",
        "        else:\n",
        "            cur.execute(\n",
        "                f\"\"\"\n",
        "                INSERT INTO {COUNTRIES_TABLE} (name, sections)\n",
        "                VALUES (%s, %s)\n",
        "                RETURNING id\n",
        "                \"\"\",\n",
        "                (country, PgJson(new_sections)),\n",
        "            )\n",
        "            new_id = cur.fetchone()[0]\n",
        "            print(f\"[DB] Inserted new country row for {country} (id={new_id}).\")\n",
        "\n",
        "        conn.commit()\n",
        "    finally:\n",
        "        conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Tcgg9_bUbo0B"
      },
      "outputs": [],
      "source": [
        "def fetch_bur_listing_page() -> BeautifulSoup:\n",
        "    resp = requests.get(BUR_LISTING_URL)\n",
        "    resp.raise_for_status()\n",
        "    return BeautifulSoup(resp.text, \"html.parser\")\n",
        "\n",
        "\n",
        "def find_status_table(soup: BeautifulSoup):\n",
        "    tables = soup.find_all(\"table\")\n",
        "    for t in tables:\n",
        "        text = t.get_text(\" \", strip=True)\n",
        "        if (\n",
        "            \"Status of BUR submissions\" in text\n",
        "            or \"Status of submission of biennial update reports\" in text\n",
        "        ):\n",
        "            return t\n",
        "    return tables[-1] if tables else None\n",
        "\n",
        "\n",
        "def normalize_country_name_for_match(name: str) -> str:\n",
        "    return re.sub(r\"[\\s\\-]\", \"\", name.lower())\n",
        "\n",
        "\n",
        "def get_latest_bur_link_for_country(\n",
        "    country: str, soup: Optional[BeautifulSoup] = None\n",
        ") -> Optional[str]:\n",
        "    if soup is None:\n",
        "        soup = fetch_bur_listing_page()\n",
        "\n",
        "    table = find_status_table(soup)\n",
        "    if table is None:\n",
        "        print(\"[SCRAPER] Could not find BUR status table.\")\n",
        "        return None\n",
        "\n",
        "    target_norm = normalize_country_name_for_match(country)\n",
        "\n",
        "    for row in table.find_all(\"tr\"):\n",
        "        cols = row.find_all(\"td\")\n",
        "        if not cols:\n",
        "            continue\n",
        "\n",
        "        party_text = cols[0].get_text(strip=True)\n",
        "        party_norm = normalize_country_name_for_match(party_text)\n",
        "\n",
        "        if party_norm == target_norm:\n",
        "            latest_link = None\n",
        "            latest_label = None\n",
        "\n",
        "            for idx, col in enumerate(cols[1:], start=1):\n",
        "                a = col.find(\"a\", href=True)\n",
        "                if a:\n",
        "                    href = a[\"href\"]\n",
        "                    latest_link = href\n",
        "                    latest_label = f\"BUR{idx}\"\n",
        "\n",
        "            if latest_link:\n",
        "                if latest_link.startswith(\"/\"):\n",
        "                    latest_link = \"https://unfccc.int\" + latest_link\n",
        "                print(\n",
        "                    f\"[SCRAPER] Latest BUR for {country}: {latest_label} -> {latest_link}\"\n",
        "                )\n",
        "                return latest_link\n",
        "\n",
        "    print(f\"[SCRAPER] No BUR link found for {country} on listing page.\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acZ7DFN3bqKx"
      },
      "outputs": [],
      "source": [
        "#  PART 2!!!!!!\n",
        "\n",
        "def normalize_country_for_filename(country: str) -> str:\n",
        "    return re.sub(r\"[\\s\\-]\", \"_\", country.upper())\n",
        "\n",
        "\n",
        "def download_bur_pdf(url: str, country: str) -> str:\n",
        "    country_norm = normalize_country_for_filename(country)\n",
        "    filename = f\"{country_norm}_BUR_latest.pdf\"\n",
        "    path = os.path.join(BUR_PDF_DIR, filename)\n",
        "\n",
        "    resp = requests.get(url)\n",
        "    resp.raise_for_status()\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(resp.content)\n",
        "\n",
        "    print(f\"[DOWNLOAD] Saved {country} BUR -> {path}\")\n",
        "    return path\n",
        "\n",
        "\n",
        "def get_or_download_bur_pdf(country: str, bur_url: str) -> str:\n",
        "    country_norm = normalize_country_for_filename(country)\n",
        "    path = os.path.join(BUR_PDF_DIR, f\"{country_norm}_BUR_latest.pdf\")\n",
        "    if os.path.exists(path):\n",
        "        print(f\"[DOWNLOAD] Using cached BUR for {country}: {path}\")\n",
        "        return path\n",
        "    return download_bur_pdf(bur_url, country)\n",
        "\n",
        "\n",
        "def load_pdf_text(path: str) -> str:\n",
        "    if not os.path.exists(path):\n",
        "        raise FileNotFoundError(f\"PDF not found: {path}\")\n",
        "    doc = fitz.open(path)\n",
        "    pages = [page.get_text(\"text\") for page in doc]\n",
        "    return \"\\n\".join(pages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oCYOG616brZO"
      },
      "outputs": [],
      "source": [
        "def extract_between(\n",
        "    text: str, start_patterns: List[str], end_patterns: Optional[List[str]] = None\n",
        ") -> str:\n",
        "    start_re = re.compile(\"|\".join(start_patterns), re.IGNORECASE)\n",
        "    m_start = start_re.search(text)\n",
        "    if not m_start:\n",
        "        return \"\"\n",
        "\n",
        "    start_idx = m_start.end()\n",
        "\n",
        "    if end_patterns:\n",
        "        end_re = re.compile(\"|\".join(end_patterns), re.IGNORECASE)\n",
        "        m_end = end_re.search(text, start_idx)\n",
        "        end_idx = m_end.start() if m_end else len(text)\n",
        "    else:\n",
        "        end_idx = len(text)\n",
        "\n",
        "    snippet = text[start_idx:end_idx].strip()\n",
        "    return snippet\n",
        "\n",
        "\n",
        "def extract_climate_transparency(text: str, country: str) -> str:\n",
        "    start_patterns = [\n",
        "        rf\"Climate transparency in {re.escape(country)}\",\n",
        "        r\"Climate transparency in the country\",\n",
        "        r\"Climate transparency\",\n",
        "        r\"Progress in the four modules of the Enhanced Transparency Framework\",\n",
        "    ]\n",
        "    end_patterns = [\n",
        "        r\"National transparency framework\",\n",
        "        r\"Baseline\",\n",
        "        r\"Official reports? to the UNFCCC\",\n",
        "        r\"Official reporting to the UNFCCC\",\n",
        "        r\"\\n[A-Z][A-Za-z ]{6,}\\n\",\n",
        "    ]\n",
        "    return extract_between(text, start_patterns, end_patterns)\n",
        "\n",
        "\n",
        "def extract_official_reporting(text: str) -> str:\n",
        "    start_patterns = [\n",
        "        r\"Official reports? to the UNFCCC\",\n",
        "        r\"Official reporting to the UNFCCC\",\n",
        "        r\"Reports submitted to the UNFCCC\",\n",
        "        r\"Table\\s*\\d+\\.?\\s*Official reports to the UNFCCC\",\n",
        "    ]\n",
        "    end_patterns = [\n",
        "        r\"Progress in the four modules of the Enhanced Transparency Framework\",\n",
        "        r\"Progress in the four modules\",\n",
        "        r\"Greenhouse gas inventory module\",\n",
        "        r\"GHG inventory module\",\n",
        "        r\"\\n[A-Z][A-Za-z ]{6,}\\n\",\n",
        "    ]\n",
        "    return extract_between(text, start_patterns, end_patterns)\n",
        "\n",
        "\n",
        "def extract_key_barriers(text: str) -> str:\n",
        "    start_patterns = [\n",
        "        r\"Key barriers\",\n",
        "        r\"Main barriers\",\n",
        "        r\"Constraints and gaps\",\n",
        "        r\"Constraints, gaps and needs\",\n",
        "        r\"Challenges and gaps\",\n",
        "        r\"Barriers to enhanced transparency\",\n",
        "    ]\n",
        "    end_patterns = [\n",
        "        r\"Progress in the four modules\",\n",
        "        r\"Greenhouse gas inventory module\",\n",
        "        r\"Adaptation and vulnerability module\",\n",
        "        r\"\\n[A-Z][A-Za-z ]{6,}\\n\",\n",
        "    ]\n",
        "    return extract_between(text, start_patterns, end_patterns)\n",
        "\n",
        "\n",
        "def build_sections_payload(text: str, country: str) -> Dict[str, Dict[str, str]]:\n",
        "    climate = extract_climate_transparency(text, country)\n",
        "    official = extract_official_reporting(text)\n",
        "    barriers = extract_key_barriers(text)\n",
        "\n",
        "    sections: Dict[str, Dict[str, str]] = {}\n",
        "\n",
        "    if climate:\n",
        "        sections[\"ClimateTransparency\"] = {\n",
        "            \"doc_type\": \"BUR\",\n",
        "            \"text\": climate,\n",
        "        }\n",
        "    if official:\n",
        "        sections[\"OfficialReportingUNFCCC\"] = {\n",
        "            \"doc_type\": \"BUR\",\n",
        "            \"text\": official,\n",
        "        }\n",
        "    if barriers:\n",
        "        sections[\"KeyBarriers\"] = {\n",
        "            \"doc_type\": \"BUR\",\n",
        "            \"text\": barriers,\n",
        "        }\n",
        "\n",
        "    return sections\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-03e247sbxI_"
      },
      "outputs": [],
      "source": [
        "def country_has_all_sections(country: str) -> bool:\n",
        "    row = get_country_row(country)\n",
        "    if not row:\n",
        "        return False\n",
        "\n",
        "    sections = row[\"sections\"] or {}\n",
        "    needed = {\"ClimateTransparency\", \"OfficialReportingUNFCCC\", \"KeyBarriers\"}\n",
        "    have = {k for k, v in sections.items() if v}\n",
        "    missing = needed - have\n",
        "    if missing:\n",
        "        print(f\"[DB] {country} is missing sections: {missing}\")\n",
        "        return False\n",
        "    print(f\"[DB] {country} already has all three sections, skipping extraction.\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def process_country(country: str):\n",
        "    print(\"\\n==============================\")\n",
        "    print(\"Processing country:\", country)\n",
        "    print(\"==============================\")\n",
        "\n",
        "    # 1. Skip if DB already has everything\n",
        "    if country_has_all_sections(country):\n",
        "        return\n",
        "\n",
        "    # 2. Find latest BUR link\n",
        "    soup = fetch_bur_listing_page()\n",
        "    bur_url = get_latest_bur_link_for_country(country, soup)\n",
        "    if not bur_url:\n",
        "        print(f\"[ERROR] Could not find BUR URL for {country}\")\n",
        "        return\n",
        "\n",
        "    # 3. Download or reuse cached PDF (Part 2)\n",
        "    pdf_path = get_or_download_bur_pdf(country, bur_url)\n",
        "\n",
        "    # 4. Extract sections from PDF text\n",
        "    text = load_pdf_text(pdf_path)\n",
        "    sections_payload = build_sections_payload(text, country)\n",
        "\n",
        "    if not sections_payload:\n",
        "        print(\n",
        "            f\"[WARN] No sections extracted for {country}. Refine regex patterns if needed.\"\n",
        "        )\n",
        "        return\n",
        "\n",
        "    # 5. Upsert into Supabase `countries.sections`\n",
        "    upsert_country_sections(country, sections_payload)\n",
        "    print(f\"[DONE] Processed {country}. Added sections: {list(sections_payload.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "lZz_aMPabzHB",
        "outputId": "07b20ff2-eb33-4e80-dcc0-4896bcb73ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==============================\n",
            "Processing country: Cuba\n",
            "==============================\n"
          ]
        },
        {
          "ename": "OperationalError",
          "evalue": "could not translate host name \"pooler.tulbxwdifnzquliytsog.supabase.co\" to address: Name or service not known\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3600438318.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcountries_to_process\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Cuba\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Jordan\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Guinea-Bissau\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcountries_to_process\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprocess_country\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2593219767.py\u001b[0m in \u001b[0;36mprocess_country\u001b[0;34m(country)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# 1. Skip if DB already has everything\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcountry_has_all_sections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2593219767.py\u001b[0m in \u001b[0;36mcountry_has_all_sections\u001b[0;34m(country)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcountry_has_all_sections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_country_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2689133320.py\u001b[0m in \u001b[0;36mget_country_row\u001b[0;34m(country)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_country_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_db_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2689133320.py\u001b[0m in \u001b[0;36mget_db_conn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_db_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     return psycopg2.connect(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0muser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDB_USER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDB_PASSWORD\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mhost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDB_HOST\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/psycopg2/__init__.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mdsn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dsn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_factory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconnection_factory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwasync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcursor_factory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcursor_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOperationalError\u001b[0m: could not translate host name \"pooler.tulbxwdifnzquliytsog.supabase.co\" to address: Name or service not known\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    countries_to_process = [\"Cuba\", \"Jordan\", \"Guinea-Bissau\"]\n",
        "    for c in countries_to_process:\n",
        "        process_country(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB0I1sjSbz_v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyN0OA8XOPkj77yzFzqmK6BT",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
